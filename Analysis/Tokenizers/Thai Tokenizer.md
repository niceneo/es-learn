## Thai Tokenizer(泰语分词器)
泰语分词器切分泰语文本成单个单词，java有提供泰语分词的算法，其他语言通常使用标准分词处理。

- WARNING 这个分词器可能不能支持所有的JREs,我们知道他能工作在Sun/Oracle和open JDK中，如果你的应用需要全手提式(搞不懂)，应该考虑使用ICU分词器。

#### Example output
```
POST _analyze
{
  "tokenizer": "thai",
  "text": "การที่ได้ต้องแสดงว่างานดี"
}
```
上述处理结果如下：
```[ การ, ที่, ได้, ต้อง, แสดง, ว่า, งาน, ดี ]```